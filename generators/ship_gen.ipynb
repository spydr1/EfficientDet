{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from ship import ShipGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from augmentor.color import VisualEffect\n",
    "from augmentor.misc import MiscEffect\n",
    "multiprocessing.cpu_count()\n",
    "tf.__version__\n",
    "\n",
    "from skimage.util import montage\n",
    "\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir='/home/minjun/Jupyter/Ship_Detection/Data/train_tfrecorder/train_data2.tfrecords'\n",
    "common_args = {\n",
    "    'batch_size': 4,\n",
    "    'phi': 1,\n",
    "    'detect_text': False,\n",
    "    'detect_ship': True,\n",
    "    'detect_quadrangle': True,\n",
    "    'preprocessing_in_gpu':False,\n",
    "    'shuffle_groups':False\n",
    "}\n",
    "train_generator = ShipGenerator(\n",
    "        'train/ship_detection',\n",
    "        file_dir,\n",
    "        gen_type = 'train',\n",
    "        misc_effect = MiscEffect(),\n",
    "        visual_effect = VisualEffect(),\n",
    "        ratio = 1,\n",
    "        **common_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.load_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = ShipGenerator(\n",
    "    'val/ship_detection',\n",
    "    file_dir,\n",
    "    gen_type='val',\n",
    "    ratio = 1-0.8,\n",
    "    shuffle_groups=False,\n",
    "    **common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "batch_inputs, batch_targets = train_generator[0]\n",
    "image1 = batch_inputs[0]\n",
    "#print(np.shape(train_generator[2][1][0][0,:,4]))\n",
    "image2 = train_generator.load_image(0)\n",
    "#image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
    "#image3 =tf.image.per_image_standardization(image2)\n",
    "fig,ax = plt.subplots(2,figsize=(50,50))\n",
    "#print(np.shape(image))\n",
    "#mean = [0.485, 0.456, 0.406]\n",
    "#std = [0.229, 0.224, 0.225]\n",
    "#image1[..., 0] += mean[0]\n",
    "#image1[..., 1] += mean[1]\n",
    "#image1[..., 2] += mean[2]\n",
    "ax[0].imshow(montage_rgb(image1))\n",
    "#print(train_generator[2][1][0][0,:,2])\n",
    "ax[1].imshow(image2)\n",
    "#ax[2].imshow(image3)\n",
    "#plt.imshow(image2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = batch_targets[1][0]\n",
    "np.shape(idx)\n",
    "print(np.shape(batch_targets[0]))\n",
    "print(np.shape(batch_targets[1]))\n",
    "print(np.shape(np.where(idx[:,0]>0)))\n",
    "print(np.shape(np.where(idx[:,1]>0)))\n",
    "print(np.shape(np.where(idx[:,2]>0)))\n",
    "print(np.shape(np.where(idx[:,3]>0)))\n",
    "print(np.shape(np.where(idx[:,4]==-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'0':0,'1':0,'2':0,'3':0}\n",
    "for i in range(train_generator.size()):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    for label in train_generator.load_annotations(i)['labels']:\n",
    "        dic[str(label)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_l = []\n",
    "for i in range(train_generator.size()):\n",
    "    o_l.append(train_generator.object_len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.array(o_l)>5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = {'labels': np.empty((0,), dtype=np.int32)}\n",
    "\n",
    "annotations['labels'] = np.concatenate(\n",
    "                [annotations['labels'],[1,2,3]])\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator[2][1][0][0,:,9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.load_image(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = tf.keras.layers.Input(shape=[64,64,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image_subtraction(image_input)\n",
    "image1[:,:,:,0] -= 103.939\n",
    "image1[:,:,:,1] -= 116.779\n",
    "image1[:,:,:,2] -= 123.68\n",
    "\n",
    "print(np.mean(image1))\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(image1[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_image_subtraction(images, means=[123.68, 116.78, 103.94]):\n",
    "    '''\n",
    "    image normalization\n",
    "    :param images:\n",
    "    :param means:\n",
    "    :return:\n",
    "    '''\n",
    "    num_channels = image_input.shape[-1]\n",
    "    if len(means) != num_channels:\n",
    "        raise ValueError('len(means) must match the number of channels')\n",
    "    channels = tf.split(axis=-1, num_or_size_splits=num_channels, value=images)\n",
    "    print(channels)\n",
    "    for i in range(num_channels):\n",
    "        channels[i] -= means[i]\n",
    "    return tf.concat(axis=3, values=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(image1))\n",
    "print(np.mean(image2))\n",
    "print(np.mean(image3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.classes.keys())\n",
    "my_dic = dict({\"0\":0,\"1\":0,\"2\":0,\"3\":0})\n",
    "\n",
    "print(train_generator.size())\n",
    "for i in range(train_generator.size()):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    for label in train_generator.load_annotations(i)['labels']:\n",
    "        my_dic[str(label)]+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.load_annotations(0))\n",
    "print(train_generator.load_annotations(0)['quadrangles'].astype(np.double).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.compute_overlap import compute_overlap\n",
    "compute_overlap(train_generator.load_annotations(0)['bboxes'].astype(np.double),train_generator.load_annotations(0)['bboxes'].astype(np.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(train_generator.load_annotations(0)['bboxes'],train_generator.load_annotations(0)['bboxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon,Rectangle\n",
    "import colorsys\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "    \n",
    "def visualize(image, boxes,figsize=(16, 16),box_type='rect'):\n",
    "        \"\"\"\n",
    "        desc : bbox와 함께 이미지를 그린다.\n",
    "        \n",
    "        -input-\n",
    "        image_id : 시각화 하기를 원하는 이미지 인덱스 번호\n",
    "        figsize : 이미지 크기\n",
    "        \"\"\"   \n",
    "        fig, ax = plt.subplots(1, figsize=figsize)\n",
    "        char_boxes=boxes\n",
    "        char_len=len(char_boxes)\n",
    "        colors = random_colors(char_len)\n",
    "        print (\"box channel : \", np.shape(boxes)[1])\n",
    "        for i in range(char_len):\n",
    "            color = colors[i]\n",
    "        # Bounding box\n",
    "            if not np.any(char_boxes[i]):\n",
    "                # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "                continue\n",
    "            \n",
    "            if box_type == 'rect':\n",
    "                if np.shape(boxes)[1] == 4 and len(np.shape(boxes))==3 : # 4 - vertex \n",
    "                    box = char_boxes[i]\n",
    "                    y_max = max(box[0, 1], box[1, 1], box[2, 1], box[3, 1])\n",
    "                    y_min = min(box[0, 1], box[1, 1], box[2, 1], box[3, 1])\n",
    "                    x_max = max(box[0, 0], box[1, 0], box[2, 0], box[3, 0])\n",
    "                    x_min = min(box[0, 0], box[1, 0], box[2, 0], box[3, 0])\n",
    "\n",
    "                else : # 2 - vertex \n",
    "                    box = char_boxes[i]\n",
    "                    y_max = max(box[1], box[3])\n",
    "                    y_min = min(box[1], box[3])\n",
    "                    x_max = max(box[0], box[2])\n",
    "                    x_min = min(box[0], box[2])            \n",
    "                width = (x_max-x_min)\n",
    "                height = (y_max-y_min)\n",
    "                print(width,height,x_min,y_min)\n",
    "                p = Rectangle((x_min,y_min), width, height, linewidth=2,\n",
    "                                      edgecolor=color, facecolor='none')\n",
    "            elif box_type == 'quad': \n",
    "                p = Polygon(char_boxes[i], facecolor=\"none\", edgecolor=color)\n",
    "            else : \n",
    "                raise (\"check the box_type\")\n",
    "                \n",
    "            ax.add_patch(p)\n",
    "        ax.imshow(image)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_image, load_annotations 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_generator.load_image(0)\n",
    "bboxes = train_generator.load_annotations(0)['bboxes']\n",
    "print(bboxes[0,1])\n",
    "visualize(image,bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## annotation 확인 및 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_generator.load_image(0)\n",
    "quadboxes = train_generator.load_annotations(0)['quadrangles']\n",
    "visualize(image,quadboxes,box_type='quad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_generator = ShipGenerator(\n",
    "        'datasets/ship_detection',\n",
    "        'train',\n",
    "        phi=1,\n",
    "        batch_size=1,\n",
    "        detect_ship =True\n",
    "    )\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    anchors = train_generator.anchors\n",
    "    batch_inputs, batch_targets = train_generator[0]\n",
    "    image = batch_inputs[0][0]\n",
    "    image[..., 0] *= std[0]\n",
    "    image[..., 1] *= std[1]\n",
    "    image[..., 2] *= std[2]\n",
    "    image[..., 0] += mean[0]\n",
    "    image[..., 1] += mean[1]\n",
    "    image[..., 2] += mean[2]\n",
    "    image *= 255.\n",
    "\n",
    "    regression = batch_targets[0][0]\n",
    "    valid_ids = np.where(regression[:, -1] == 1)[0]\n",
    "    boxes = anchors[valid_ids]\n",
    "    deltas = regression[valid_ids]\n",
    "    class_ids = np.argmax(batch_targets[1][0][valid_ids], axis=-1)\n",
    "    mean_ = [0, 0, 0, 0]\n",
    "    std_ = [0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "    width = boxes[:, 2] - boxes[:, 0]\n",
    "    height = boxes[:, 3] - boxes[:, 1]\n",
    "\n",
    "    x1 = boxes[:, 0] + (deltas[:, 0] * std_[0] + mean_[0]) * width\n",
    "    y1 = boxes[:, 1] + (deltas[:, 1] * std_[1] + mean_[1]) * height\n",
    "    x2 = boxes[:, 2] + (deltas[:, 2] * std_[2] + mean_[2]) * width\n",
    "    y2 = boxes[:, 3] + (deltas[:, 3] * std_[3] + mean_[3]) * height\n",
    "    for x1_, y1_, x2_, y2_, class_id in zip(x1, y1, x2, y2, class_ids):\n",
    "        x1_, y1_, x2_, y2_ = int(x1_), int(y1_), int(x2_), int(y2_)\n",
    "        cv2.rectangle(image, (x1_, y1_), (x2_, y2_), (0, 255, 0), 2)\n",
    "        class_name = train_generator.labels[class_id]\n",
    "        label = class_name\n",
    "        ret, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.3, 1)\n",
    "        cv2.rectangle(image, (x1_, y2_ - ret[1] - baseline), (x1_ + ret[0], y2_), (255, 255, 255), -1)\n",
    "        cv2.putText(image, label, (x1_, y2_ - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    cv2.imshow('image', image.astype(np.uint8)[..., ::-1])\n",
    "    cv2.waitKey(0)\n",
    "    # 36864, 46080, 48384, 48960, 49104\n",
    "    # if first_valid_id < 36864:\n",
    "    #     stride = 8\n",
    "    # elif 36864 <= first_valid_id < 46080:\n",
    "    #     stride = 16\n",
    "    # elif 46080 <= first_valid_id < 48384:\n",
    "    #     stride = 32\n",
    "    # elif 48384 <= first_valid_id < 48960:\n",
    "    #     stride = 64\n",
    "    # else:\n",
    "    #     stride = 128\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
